AWS Important Notes - 
1) IAM - 
2) EC2 Instance - AMI(OS) + security group + Instance Size(CPU + RAM) + Storage + EC2 User data.
3) EBS - Elastic Block Store(Volume) is a network drive you can attach to your instances while they run 
   and instances to persist data, even after their termination, they are bound to a specific availability 
   zone and could detached from one EC2 and attached another EC2, ESB can be attached to multiple instances. 
   Make an Amazon EBS volume available for use - https://docs.aws.amazon.com/ebs/latest/userguide/ebs-using-volumes.html 
   .One could take snapshots and copy it across the AZ or region. 
4) AMI - Amazon Machine Image - They are a customization of an EC2 instance, are built for a specific region and can be copied to other regions.
5) EC2 Instance Store - Instead of EBS volume which are network drive with good but limited performance, 
   so for that we use EC2 IS which is a high-performance disk. If stopped losses the data and good for 
   temporary content, good for buffer, cache and scratch data. 
   VPC and Subnet
    A VPC (Virtual Private Cloud) is a virtual network dedicated to your AWS account. 
   It is logically isolated from other virtual networks in the AWS Cloud. You can specify an IP address range for the VPC, add subnets, add gateways, 
   and associate security groups.
   A subnet is a range of IP addresses within your VPC. Some key points about subnets:
   a) Subnets reside in a single Availability Zone and cannot span multiple zones.
   b) You can launch AWS resources, such as EC2 instances, into specific subnets. 
   c) Subnets can be either public or private, depending on their CIDR block and routing configuration.
   d) Public subnets have a route to the internet via an Internet Gateway, while private subnets do not.
   e) You can connect subnets to the internet, other VPCs, and your own data centers using various gateway types and routing configurations.
6) EFS - Elastic File System is a managed network file system that can be mounted on 100s of EC2. 
   Work with Linux EC2 instances in multi-AZ via EFS Mount Target. There is no capacity planning, 
   highly available and scalable but expensive.
   - EFS Infrequent Access is a storage class that is cost optimized for flies not accessed 
     every day based on their usage last time (60 days) enabled with lifecycle policy.
Scaling and Elasticity section -
7) Autoscaling and Load Balancing
  - basics -
      Scalability and Elasticity - 
        1st Is ability to scale up or scale out.
        2nd Is that there will be auto-scaling for system to scale based on load.
  - creation of load balancing -
      Types -
      1) Application LB - Choose an ALB when you need a flexible feature set for your applications
         with HTTP and HTTPS traffic. Operates on the request level, ALB provide advanced routing and 
         visibility features targeted at application architectures, including microservices, containers.
         Used for HTTP and HTTPS load balancing. They are the best-suited for this kind of traffic.
      2) Network LB - Choose a Network Load Balancer when you need ultra-high performance, 
         TLS offloading at scale, centralized certificate deployment, support for UDP, and static IP addresses 
         for your applications. Operating at the connection level, Network Load Balancers are capable 
         of handling millions of requests per second securely while maintaining ultra-low latencies.
      3) Geatway LB - Choose a Gateway Load Balancer when you need to deploy and manage a fleet of third-party 
         virtual appliances that support GENEVE. These appliances enable you to improve security, compliance, 
         and policy controls.
      Basic Configuration -
       1) Name the balancer.
       2) Scheme - a) Internet Facing - Routes requests from clients over the the internet to targets. Requures a public subnet.
                   b) Internal - Routes requests from the clients to targets using private IP addresses.
       3) Load Balancer IP Address Type - IPv4, DualStack, DualStack without public IPv4.
       4) Network Mappings - routes to targets in the selected subnets and in accordance with your IP address settings.
          Availability mappings - 2 zones and one subnet per zone.
       5) Security Groups - Is a set of firewall rules that control the traffic to your balancer.
       6) Listeners adn routing - A listener is a process that checks for connection requests using the port and protocol you configure. 
          The rules that you define for a listener determine how the load balancer routes requests to its registered targets.
          Here we create traget group - basic configuration could be instances, IP addresses, lambda function, application LB, portocol - port
          VPC with protocol version. Optimize with service integration.
       7) Adding the targets by going into the console for it and selecting the instances.
       8) Test it.
    ASG - is to scale out and in to match the load on the application and website. And ensure the min. no. of machines.
    Automatically register new instances to a load balancer and Replace unhealthy instances.
    ________________________________________________________
    EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2
    ________________________________________________________
    |Min. size|                     |                      | <- this ASG
    |Actual Size / desired capacity||  Scale out as Needed |
    |                Max. Size                             |
    We use ASG with load balancer.
                            __LB_
                           / /|\ \ 
    ______________________/ / | \ \_________________________
    EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2 EC2
    ________________________________________________________
    |Min. size|                     |                      | <- this ASG with LB
    |Actual Size / desired capacity||  Scale out as Needed |
    |                Max. Size                             |
  - creation auto scaling -
       1) Choose name and launch template or configuration. And have the source template if required.
       2) Create the launch template - 
          a) Set the application and OS images - select the AWS Linux image and select the required architecture.  
          b) Choose the instance type.
          c) Key pair(login)(optional).
          d) Network settings - subnet and security group. And also can do advanced network configuration.
          e) EBS volume - could be added more.
          f) Optional - resource tags.
          g) Advanced details - 
             For now uadd user data - a simple bash script for the EC2s.
       3) After that, in the network have VPC and Availability Zones and subnets.
       4) Add the load balancing and attach the load balancer. One could add VPC Lattice integrations. There are health checks too.
       5) Configure group size and scaling, and can add automatic scaling and to track its target, along with instance maintenance policy.
    There are many things that could be there like lifecycle hooks, Warm pool(pre-initializing EC2 instances). 
    ASG scaling strategies - Manual, Dynamic -> Simple Scaling, Traget Tracking, Scheduled Scaling - Predictive Scaling using ML.
8) ELB - Elastic Load Balancer - Comes under EC2 and it is managed load balancer.
   Important points of load balancer - 
   a) Spread load across multiple downstream instances.
   b) Expose single point of access (DNS) to our app. 
   c) Seamlessly handle failures of downstream instances.
   d) Regular health performiance.
   e) Provide SSL termination (HTTPS) for our website.
   f) High availability across zones.
   Using of ELB - It is a managed load balancer.
   - 4 Kinds of Load Balancers in AWS -
     1) Application LB (HTTP/HTTPS/RPC) - Layer 7, routing features, static DNS(URL). 
     2) Network LB (ultra-high performance, allows for TCP and UDP) - Layer 4 - Static IP via Elastic IP.
     3) Gateway LB (GENEVE Protocol) - Layer 3 - this protocol on IP Packets, routes traffic to Firewalls set by us, Intrusion detection. 
     4) Classic LB - Layer 4 & 7 (retired).
----------------
9) S3 - Backup and storage, disaster recovery, hybrid cloud storage, media hosting, 
   application host, archive, data lakes, software delivery, static website. Allows people to store 
   objects(files) in buckets(directories). Buckets are defined at region level and must have globally 
   unique name. Objects have a key which is the full path and composed of prefix + object name. 
   They could be long names that have slashes. Values of Object are the content of body and if < 5GB, 
   must use multi-part upload. Metadata (list of text key / value pairs - system or user metadata). 
   Tags are also used (Unicode key / value pair - up to 10)- useful for security / lifecycle. 
   Version based Id is there too if enabled. IAM Policies are used for User-Based access 
   and Bucket Policies is a bucket wide from S3 console - allows cross accounts. 
   Object and Bucket Access Control List - less common. Bucket Policy to grant public access to 
   bucket and force objects to be encrypted at upload. Static Web Hosting can be enabled and S3 
   bucket's objects can be accessed. We can do versioning at the bucket level, same key overwrites 
   will change the version so we version the buckets instead, also allows easy roll back. 
   Replication requires versioning enabled and we can do 2 types - CRR(Cross region replication) 
   and SRR(Same region replication), copying is async. and IAM permissions must be given to S3.
   Storage Class - Standard, Standard - Infrequent Access, One Zone - IA, Glacier(Instant, Flexible, 
   Deep Archive), Integlligent Tiering. Lifecycle rule lets us automate things like changing between 
   various storage class. Choose the actions we want to perform by the rule like moving between storage class or delete. 
   Choose transitions to move current versions of objects between storage 
   classes based on your use case scenario and performance access requirements. 
   These transitions start from when the objects are created and are consecutively applied.
   S3 Encryption - Server-side Encryption(after uploading) and Client-side Encryption(before upload).
   IAM Access Analyzer for S3 for only few to have access to our buckets and evaluates the bucket Policies,
   ACLs, Access point Policies.
10) Snow Family - Highly secure, portable devices to collect and process data at edge,
    and migrate data into/out of AWS. Has 3 services - snowcone, snowball edge, snowmobile.
    Edge Computing - 
    1) Snowcone & Snowcone SSD (smaller) - 2 CPUs, 4 GB of memory, wired or wireless access.
    2) Snowball Edge - Compute Optimized - 104 vCPU, 416 GiB RAM, Optional GPU, 28 TB NVMe. Storage Clustering. 
    3) Snowball Edge - Storage Optimized - Up to 40 vCPUs, 80 GiB of RAM, 80 TB storage, 
       Up to to 104 vCPUs, 416 GiB of RAM, 210 TB NVMe storage.
11) AWS Storage Cloud Native Options - 
    Block - Amazon EBS, EC2 Instance Store
    File - EFS
    Object - S3, Glacier
12) Storage Gateway - Hybrid storage service to allow on-premises to seamlessly use AWS Cloud
    Types - 
    1) File Gateway
    2) Volume Gateway
    3) Tape Gateway
13) RDS - Reational Database Service, it's a managed DB service for DB use SQL.
    Automated provisioning, OS patching, continuous backups and retore to
    specific timesatamp, multi-AZ setup for disaster recovery, maintenance windows, 
    monitoring, scaling capability, storage backed by EBS, replica reads, no SSH into instances.
    We create RDS and take its snapshot where we can restore, copy, delete, share, migrate.
    RDS Sol. Arch. - Elastics Load Balancer-->Multi-EC2 instances-->RDS.
    RDS Deployments - Read Replicas -> Helps in rapid scaling, can create upto 15 replicas, data written to only main DB.
                      Multi-AZ -> Fail-over in case of AZ outage, data read/write to main DB only.
                      Multi-Region -> Combine the above two over mu regions.
14) Aurora - PSQL, MySQL are both supported as Aurora DB and it is cloud optimized and claims 5x performance
    imporvement over MySQL on RDS and 3x over PSQL on RDS. Aurora storage automatically
    grows in increments of 10GB, up to 128TB. Not in free tier. There is also Aurora 
    Serverless which has automated database instanisation and auto-scaling based on actual
    usage, no capacity planning needed, least management overhead and pay per second.
15) ElastiCache - Managed Redis, Memchached, caches are in-memory databases with high performance and low latency.
    Helps reduce load off databases  for read intensive operations.  
    Arch. - ELB - EC2 with ASG |--> ElastiCache
                               |
                               |--> RDS  
16) Dynamo DB - Fully managed high availability and replication. AWS's NoSQL Key-Value database.
    Scales massively for serverless workloads. Single Digit milisecond latency with 100s TB of storage.
    Integrated with IAM. Has Standard and IA Table class. Has DynamoDB Accelerator which is a 
    in-memory database for DynamoDB and improves 10x from milisecond latency to microsecond.
    Here the table, the primary key is the hash of partition key used for retrieval of items from the 
    table and allocate data across hosts for scalability and availability, and sort key which for 
    optional that allows us to sort or search among all items sharing the same primary key.
    Global Tables - make it accessible with low latency in multi-regions.
17) RedShift - It's OLAP - online analytical Processing. It serves as data warehousing.
    Load data every hour, columnar instead of row based storage, 10x better performance than others,
    massively parallel query execution. Has SQL interface for performing queries and BI tools 
    such as AWS QuickSight or Tableau integrate with it. Has a serverless option and offers
    automatic provisions and scales data warehouse underlying capacity. Run analytics workloads
    without managing data warehouse infra.
18) EMR - Elastic MapReduce helps create Hadoop Clusters for Big data and can be made up of 100s
    of EC2 instances and also supports Apache Spark, HBase, Presto, Flink. It takes care of provisioning
    and congiguration and auto scaling is there too.
19) Athena - Serverlesss query service for performing analytics aganist S3 objects and uses
    standard SQL query and supports CSV, JSON, ORC, Avro and Parquet. Cost - $5.00 per TB of data
    scanned and use compressed or columnar data for cost-savings. 
20) QuickSight - Serverless machine learning-powered business intelligence service 
    to create interactive dashboards.
21) DocumentDB - AWS implementation of MongoDB, fully managed, highly available with replication across 3 AZ.
    It automatically increments by 10 GB.
22) Neptune - Managed graph database and used for various social networks. And highly available across 3 AZ,
    with up to 15 read replicas. Has milisecond latency.
23) TimeStream - Fully managed fast, scalable, serverless time series database. Automatically scale up/down
    to adjust capacity. Store and analyze trillions of events per day, 1000s times faster and 1/10th the cost
    of RD. Built-in time series analytics functions. 
24) QLDB - Quantum Ledger DB and used for recording financial transactions and fully managed serverless, 
    immutable system and used for review history, replication across 3 AZ.
25) Managed Bkockchain - Is a managed service to join public blockchain networks or create your own scalable 
    private network. Compatible with Hyperledger Fabric and Ethereum.
26) Glue - Managed ETL service, useful to prepare and transform data for analytics, fully serverless.
27) Database Migration Service - Source DB -> EC2 running DMS -> Target DB, it is self healing, resilient. 
    Homogenous and heterogenous migrations can be performed.
28) ECS - Elastic Container Service and launch containers on AWS, we need to provide provision and maintain
    the infra and AWS takes care of starting/stopping containers. Integrates with application
    load balancer. 
29) Fargate - Launch docker containers on AWS and then provision is maintained AWS. It is serverless offering and AWS just runs 
    containers for us based on CPU/RAM we need. 
30) Lambda - No servers to manage and limited in execution time and runs on demand. Scaling is automated.
    Easy pricing, pay per request and compute time. Integrated with other services and event-driven
    and works with other langauges, easy monitoring via CloudWatch and easy to get resources per functions up to 10GB of RAM.
    It has a container image. To create we can do it from scratch, use blueprint or container image is used. Lambda also creates 
    IAM role for our function we can use existing role or use templates. We can create tests where a new event and it is in JSON format.
    We can add trigger, layers and destination. We get priced per request(call) and compute time(duration)
31) API Gateway - Fully managed service for developers to easily createm publish, maintain, monitor, and secure APIs. Serverless
    and scalable, supporting RESTful and Websocket APIs. Supports the following - 
    a) security
    b) auth
    c) API throttling
    d) monitoring
    e) API keys
32) Batch - Fully managed batch processing at any scale, efficiently run 100,000s of computing batch jobs.
    It automatically launch EC2 instances. It provisions the right amount of memory and compute. We only 
    schedule and write the process and AWS Batch does the rest. The jobs are docker image on EC2 instance.
34) Lightsail - It is virtual, storage, databases and networking, low and predictable pricing.
    Simpler alternative to using EC2, RDS, ELB, EBS, Route 53. But has less high availability, 
    Limited AWS Integrations.
35) CloudFormation - Declartive way of outlining your AWS infra, for any supported resources.
    Creates the resources defined in the defined order and with exact configuration.
    Benefits -
     1)  IaC - No resource are manually created.
     2) Cost - Using identifiers in the stack with tags we know what resource cost how much.
     3) Productivity - Ability to destroy and re-create infra on the cloud on the fly. Automated
        generation of Diagram form the templates, Declarative programming.
36) CDK - Define cloud infra using familiar languages. The code is then compiled into CF format.
    Allows to deploy infra and application runtime at the same time. Which is great for Lambda functions
    and Docker containers in ECS and EKS.
37) BeanStalk - It is a developer centric view of deploying an application on AWS.
    It is a PaaS. We have full control of configuration as it is a managed service so most of the configuration
    can be automatically created along with load balancing and autoscaling, provisioning and monitoring.
    While creating a new application we have 2 options - web app or worker service. Also we have autogenerated or custom
    domain names. We then can choose the platform and upload code for that platform or use sample code. And we get presets
    , which are nothing but starting configuration of the instances. Using IAM and EC2 instance profiles are tied to an IAM 
    policy which is used for service access configuration. We can get new service role and custom make EC2 instance profiles.
38) CodeDeploy - To deploy our applications automatically and it works with EC2 and On-Prem Servers as well as Hybrid.
    We provide servers / instances configured before hand with CodeDeploy Agent.
39) CodeCommit - Before pushing the application code to the servers, it is stored in repository, it is competing service 
    to GITHUB.
40) CodeBuild - Building the code in the cloud. Here we run test, compile and produce packages and pull it from the CodeCommit.
    It is fully managed, severless, pay-as-you-go, secure, continuously scalable and highly available.
41) CodePipeline - Orchestrate the different steps to have the code automatically pushed to production.
    It is fully managed, compatible with CodeCommit, CodeBuild, CodeDeploy, Elastic BeanStalk, CloudFormation, GITHUB, 3rd-party
    services and custom plugins.
42) CodeArtifact - Software packages depend on one other to be built and create new ones, so to store and retrive them is called
    artifact management which is what this service does, and it is fully managed, scalable, secure, cost-effective and works with 
    dependencies management tools like NPM, Maven, NUGET, Gradle, PiP, Yarn, etc.
43) CodeStar
44) Cloud9 - It is a cloud based IDE for writing, running, debugging code.
45) System Manager - Helps manage EC2 and On-Premises systems at scale. Another hybrid AWS service, get operational insights about state of your infra.
    Suite of 10+ produts. Most Important Features - 
      a) Patching automation for enchanced compliance.
      b) Run commands across an fleet of servers.
      c) Store parameter configuration with SSM Parameter Store.
    SSM Session Manager - No SSH keys, access or hots nedded. No port 22 for better security. SSM Agent is EC2 instance, supports Linux and other OSs.
    Send session log data to S3 or CloudWatch logs.
    System Manager Param Store - secure storage for config and secerts, contorl access permissions using IAM. Version tracking and Encryption.
46) Route 53 - It is a managed DNS. DNS stands for Domain Name System which is a collection of rules and records which client understand how to reach a 
    server through URLs. Routing policies - Simple RP with no health check, weighted RP allows for distributed traffic across multiple institute instances,
    each wieght indicates the % of traffic each instance will get form the client and we have health checks here. Latency RP looks at user's location and then 
    redirects them to the closest server, this is to reduce latency via Route 53, finally there is Failover RP for distater recovery, here if primary instance 
    fails then the traffic will be redirected to failover instance, this is done by Route 53.
    Route 53 features are (non exhaustive list): Domain Registration, DNS, Health Checks, Routing Policy.
    Setup process - 
    1) Go to the dashboard in route 53 page.
    2) Navigate to Register Domain and type the domain and it will check for availability, if so pay a price for it on yearly basis.
    3) Register contact details of yours and it will create the domain.
    4) Go to hosted zone details.
    5) For example set-up 2 EC2 instance in different regions and put their IPv4 addresses along with AZ name.
    6) Then go back to route 53 and create record and give value of IPv4 address.
    7) Choose a routing policy like simple routing, weighted, latency, etc.
    8) Region is selected along with string as Record ID. Then put Record name as what is needed and Record type.
    9) Test the outcome.
47) CloudFront - It is CDN, improves read performance, content is cached at the edge. DDoS protection, AWS WAF, integration with Shield. Usage as ingress in 
    S3 bucket, custom Origin. It uses CloudFront Origin Access Control (OAC). It provides Global Edge Network and served at the edge.
    File cached via TTL (Time to Live).
    1) On CloudFront dashboard go create distribution.
    2) Then choose origin domain, here we choose the URL of the S3 bucket.
    3) Also one could add Custom  header to include in the rquests and can enable origin shield.
    4) Keep origin access as Public, there are other options like Origin access control and legacy access identities.
       We will choose Origin control settings and create a OAC for S3 bucket and we write down in S3 permissions. And CloudFront  will 
       provide the policy.
    5) Cache key and origin requests options - Cache policy and origin request policy, Legacy cache settings and origin request policy.
    6) Also for cache behaviour - path pattern, compress objects automatically.
    7) Viewer - protocol policy, allowed HTTP methods, retruct viewer access. 
    8) Response headers policy - optional - it has CORS policies.
    9) Choose edge function to associate with this cache behaviour, CloudFront event will invokes the function.
    10) WAF - option - enable security protection, and not able protections.
    11) Other settings price - optional, alternate domain name - optional, custom SSL certificate - optional, supported HTTP versions, 
       Default root object which is base file - optional and also standard logging and IPv6. 
48) S3 Transfer Accceleration with Edge location that carry the objects closer to another bucket, so that it could be closer to the location.
49) AWS Global Accelerator - Improve global application availability and performance using the AWS global network.
    We leverage the AWS's internal network to optimize routing to our application. Quite similar to CloudFront in terms of delivering the content.
    But no caching, proxying packets at edge. Improves performance for different types of apps over TCP or UDP.
    Good for HTTP cases where we need static IP address, required deterministic fast regional failover.
50) AWS Outposts - Hybrid Cloud is used by many companies we can distribute between -
    a) One on AWS
    b) On-premises - Here Outposts are AWS server racks and provide all the services including management on on-premises.
    Benefits -
    a) Low latency access to on-premises.
    b) Local data processing.
    c) Data residency
    d) Easier migrations
    Some services that work on Outposts - EC2, EBS, S3, EKS, ECS, RDS, EMR.
51) WaveLength Zone - Are infra deployments embedded within the telecommunication provider's datacenters at the edge of 5G network.
    Brings AWS services to the edge of 5G network. This for ultra-low latency through 5G network, without leaving Communication Service Provider's
    network. Allows high-bandwidth and secure connection to the parent AWS Region.
52) Local Zones - Places AWS compute, storage, database, and other selected AWS service closer to end users to run latency-sensitive app.
    Extend the VPX to more locations.
    When you create a new AWS Local Zone, you would need to create a new subnet within that Local Zone and associate it with your VPC:
    a) First, you need to enable the Local Zone in your AWS Region. This can be done through the AWS Management Console or the AWS CLI.
    b) Once the Local Zone is enabled, you can create a new subnet within that Local Zone. When creating the subnet, you would specify 
       the Availability Zone (AZ) as the Local Zone.
    c) After creating the subnet, you can associate it with your existing VPC. This can be done through the console or the AWS CLI using the 
       create-subnet command.
    d) You can then associate security groups with the resources (e.g., EC2 instances) launched in the subnet within the Local Zone, 
       just like you would for any other subnet in your VPC.
53) SQS - Simple Queue Service. A producers sends messages to this queue and and the queue poll messages to the cosumers. It is fully managed, used for
    decoupling applications. Scales from 1 message per second to 10,000s per second, it can also retain messages between 4 to 14 days with limitations 
    on number of messages through the queue could be sent. Messages deleted after customers read and has latency lower then 10ms. It also works on FIFO queue model.
    Setup - 
    a) Choose type of queue - standard with once delivery and best efforts ordering and FIFO with delivery and once only processing.
    b) A name.
    c) Set visibility timeout, message retention report, delivery delay, max. message Size, receive message wait time.
    d) For encryption - 1st we have server side encryption, and key type either ne SSE-SQS or SSE-KMS.
    e) Access policy could be 2 - 
       1) Basic - Has the settings for queue owner or specified AWS accounts as sender and receiver.
       2) Advanced - Could be defined using JSON.
    f) Redrive allow policy & Dead letter policy - Helps identify which source queues can use this queue as dead-letter queue.
       Dead letter means a queue that other queues can target for messages that were not successfully processed  
54) Kinesis - Real-time big data streaming, it is managed service collect, process, analyze real-time streaming data at any scale.
    There are 2 more things Kinesis Firehose, Data Streams, Analytics and Video Streams.
55) SNS - Event publishers sends to one SNS topic and many event subscribers as we want to listen to the SNS topic notifications.
    Each subscriber to the topic will get all the messages. Up to 12,500,000 subscriptions per topic and 100,000 topics limit.
    Setup - 
    a) Types of SNS - 
       1) Name and Display name.
       2) FIFO - Strictly-preserved message ordering.
                 Exactly-once message delivery.
                 High throughput, up to 300 publishes/second.
                 Subscription protocols: SQS.
          Standard - Best-effort message ordering.
                     At-least once message delivery.
                     Highest throughput in publishes/second.
                     Subscription protocols: SQS, Lambda, HTTP, SMS, email, mobile application endpoints.
    b) Encryption - optional - AWS KMS Key.
    c) Access policy - optional - Choose methods - 
    d) Basic - options for who will be the publisher and subcriber - topic owner, specific endpoint, specific AWS account.
    e) Advanced - A JSON config file.
    f) Data Protection policy - basic & advanced with JSON - 
        a) Configuration mode - basic and advanced.
        b) Custom data identifiers config.
        c) Deny config.
        d) De-identify config.
        e) Audit config to audit sensitive data.
    g) Delivery policy (HTTP/S) - To retry to deliver HTTP/S endpoints.
    h) Delivery status logging - Log status delivery for various protocols - SQS, Lambda, Kinesis Firehose, HTTP/S,  Platform endpoint.
    Creating Subscription - 
    a) Fill in details like Topic ARN, Protocol, Endpoint.
    b) Subscription filter policy - optional - Scope could be applied attributes or body of message.
    c) Redrive policy - optional - Edit the queue we wnat to have for dead-letter.
    Publish message to pic -
    a) Message details - put in the subject and time to live as optional.
    b) Message body - There are 2 structures - 
       1) Identical payload for all delivery protocol and just put in the message.
       2) Custom payload for each protocol with JSON.
    c) Message attributes - could be type, name, value.
56) MQ - Traditional applications running from on-premises may use open protocol such as - MQTT, AMQP, STOMP,
    OpenWire, WSS. When mirgation to the cloud, instead of redoing things we use them direclty with AWS MQ.
    It is a managed message broker for KAFKA, RABBITMQ, ACTIVEMQ. But doesnot scale, has failover and also run in multi-AZ.
    Has both queries and topic features.
57) CloudWatch Metrics - Provides metrics for every services in AWS. We us dashboards.
    a) EC2 instances - For CPU utilization, status checks, networks, detailed metrics available for every 5 min.
    b) EBS volume - For disk writes/reads.
    c) S3 buckets - For we track - BucketSizeBytes, NumberOfObjexts, AllRequests.
    d) Billing.
    e) Service limits - How much the API will be used.
    f) Custom metrics - push own metrics.
    Alarms - Used to trigger notifications for any metric, for actions like ASG, EC2, SNS.
    There are various options for samoling and one can choose the period on which evaluate an alarm.
58) VPC - Virtual Private Cloud. It includes - VPC, Subnet, Internet Gateways, NAT Gateways, 
    Security Groups, Network ACL, VPC Flow Logs, VPC Peering, VPC Endpoint, Site to Site VPN, Direct Connect, Transit Gateway.
    IP Addresses in AWS - We have IPv4(Public/Private), this is added EC2 instance in the network configuration. Elastic IP allows
    a fixed public IPv4 address to EC2 instance.
    a) VPC - A private network to deploy your resources(reginal resources).
    b) Subnets - Allows you to create partition network inside your VPC(Availability Zone resource).
       Public Subnet - accessible from internet, Private Subnet - not accessible from the internet. 
       To have access between subnets and internet we use Route Tables.
       ______________________________________
      | AWS Cloud                           |  
      |  __________________________________ |                                 
      |  | Region                         | |
      |  | ______________________________ | |   
      |  || VPC CIDR Range               || |
      |  ||  ______                      || |
      |  || |AZ    |                     || |
      |  || |Public|                     || |
      |  || |Prvate|                     || |
      |  ||______________________________|| |
      |  |________________________________| |
      |_____________________________________|
    c) Internet Gateways - Helps our VPC to connect with the internet.    
    d) NAT Gateways and Intances - NAT(Network Address Translation) are managed AWS services used to enable instances in 
       private subnet to connect to internet or other services while preventing the internet to initiate 
       a connection to those instances.
       Gateways provide high throughput and are designed to scale automatically based on traffic. The instance is an EC2
       instance to perform the NAT functions for private subnets, it is then registered to the route table to go through the NAT instance.   
       Flow Logs - 1. VPC Flow Logs
                   2. Subnet Flow Logs
                   3. Elastic Network Interface Flow Logs
       VPC Peering - Connect VPCs privately using AWS's network. And they behave as if they were of the same network.
                     The CIDR should not overlap.
                     To create Peer - 
                     1. Name the peer network.
                     2. Select a local VPC to peer with the requester - a vpc id is selected.
                     3. Select another VPC to peer with.
       VPC Endpoint - Allows us to connect to AWS network using private network instead of public network.
                      Enchances security and provides low latency to access AWS services. The endpoint gateway is used 
                      connect to S3 & DynamoDB. Endpoint interface is for the rest of the services.
                      To create an endpoint - 
                      1. We name the endpoint and choose service category - AWS Services, Marketplace Services, Other endpoint services,
                         PrivateLink Ready partner, EC2 instance connect.
                      2. Choose the serivce to which you want to connect and whether it is interface or gateway.
                      3. The the VPC to which the endpoint needs to be added to.
                      The difference between Interface and Gateway is -
                      1. Gateway supports connectivity to S3 and DynamoDB only whereas Interface gives a wide-spread access.
                      2. Gateway requires no Elastic Network Interface, Interface acts as entry point to reach AWS PrivateLink 
                         supported services.
                      3. Interface uses Private IP address and allows on-premises as well as cross-region,
                         Here cross region is not allowed.
                      4. Interface is associated at subnet level and allows direct flow to the specific services. Gateway is at VPC level, routes
                         traffic throught the gateway endpoint to the specific services.  
Note:- Regions - For deploying applications and infra
       AZ - Made of multiple data centers
       Edge Locations - For content delivery as close as possible to users
       CIDR - Classless Inter-Domain Routing 
              Structure - Nerwork_Address/Host_Address 
       ACL - Access Control List
       DHCP - Dynamic Host Configuration Protocol
59) Network ACL & Security groups - 
        Network ACL - Is a firewall that controls traffic from and to subnet. It has rules to allow & deny access to the subnet.
                      They are attached to subnet levels and the rules only include IP addresses. It is stateless - return traffic must be allowed
                      by the rules. The rules are processed in order to allow the traffic and they automatically applied to all the instances
                      in the subnet it's associated with.
        Security Groups - A firewall that controls traffic to and from an EC2 Instance. Can have only ALLOW rules. Rules include IP and other 
                          security groups. It is stateful - return traffic allowed regardless of rules. Rules evaluated before traffic enters
                          and applies to an instance only if someone specifies it at the launching of an instance.
    ____________________________
   |VPC                         |
   |  _________________________ | 
   | |Public Subnet            ||       
   | |  NACL                   ||
   | |  _____________________  ||
   | | |      Security Group | ||
   | | |                     | ||
   | | |      EC2            | ||
   | | |                     | ||
   | | |_____________________| ||
   | |_________________________||
   |____________________________|   
60) AWS PrivateLink - Most secure and scalable way to expose a service to 1000s of VPCs.
    Does not require VPC peering, internet gateway, NAT, route tables.
    We can connect to private network of AWS's customers.
61) AWS Shield Standard/Advanced - Protects aganist DDoS atttck for no cost. Advanced is more premium(24/7).
    Advanced provides protection from sophisticated attack on EC2, ELB, CloudFront, Global Accelerator, Route 53.
62) AWS WAF - Filter specific requests based on rules. WAF(Web Application Firewall) - Protects from common web exploits aka layer 7.
    Layer 7 is HTTP, & deployed on ALB, API Gateway, CloudFront. We define rules in Web ACL, including IP addresses, HTTP headers & body or userguide
    strings. Size & geo-constraints. Protects aganist SQL injection or XSS attacks. Rate-based rules aka based on the
    occurance of events for DDoS.
63) CloudFront & Route 53 - Availability protection using global edge newtwork, combined with the Shield, 
    provides attack mitigation at the edge.
64) Network Firewall - Protects entire VPC from Layer 3 to 7.
    Can inspect - VPC-VPC traffic, outbound and inbound traffic, to/from direct connect and site-to-site VPN. 
65) Firewall Manager - Manage security rules in all accounts of AWS. 
    Security Policy - 1. Common set of security rules - VPC security groups for VPC, ALB, etc. 
                      2. WAF rules.
                      3. Shield Advanced.
                      4. Network Firewall. 
    Rules are applied to new resources as they are created automatically and for future accounts too.
66) KMS - Key Management Service. To manage encryption for keys used for data in transit/rest.
    One can opt-into it - EBS Volumes - encrypt volumes, Server-side encryption of data same for RDS, EFS, RedShift.
    In some places it is automatically enabled - Stroage Gateway, CloudTrail, S3 Glacier.
    It is the software side of encryption.
    Types keys in KMS - 
    1. Customer Managed Keys - Create, manage & used by customer, rotation of policy & bring your own key allowed.
    2. AWS Managed Keys - Created, managed and used on customer's behalf by AWS.
    3. AWS Owned Key - Collection of CMKs that an AWS serivce owns & manages to use in multiple accounts. Used for user resource protection.
    4. CloudHSM Keys - Keys generated from your own CloudHSM hardware device. Cryptographic operations are performed within CloudHSM cluster.
67) CloudHSM - Provisions encryption hardware. HSM(Hardware Security Moudle).
68) Secerts Manager - Meant for storing secerts, has capability to rotation of secerts every X days. Automating generation of secerts on rotation.
    Secerts are encrypted using KMS, & intergates with RDS service. Meant for RDS intergation.
69) Artifact - Portal provides customers on-demand access to AWS compilance documentation and agreements.
    The artifact reports that allow us to download AWS security and compilance from 3rd party auditors. Then there are agreements that 
    allow us to review, accept and track their status.
70) GuardDuty - It is an intelligent threat discovery to protect our account. Uses ML algorithms for anomaly detection, 3rd party data.
    We can input data including - CloudTrail, VPC Flow logs, DNS logs. And for notifications we can setup of EventBridge.
71) Inspector - Automated Security assessments, EC2 instances - leveraging AWS System manager agent, network accessiblilty, running OS for vulnerabilities.
    For container images push to ECR, i.e. to assess the containers being pushed. Can be used for Lambda function.
72) AWS Config - Helps with auiditing and recording compilance of our AWS resources. Records configuration and changes over time.
    Possibility of storing config data into S3. Makes sure that we know what kind of access different users have to resources. One can use SNS for any changes.
    It is pre-region service. 